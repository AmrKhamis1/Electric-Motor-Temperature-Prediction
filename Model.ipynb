{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= IMPORTS =================\n",
    "# Import essential libraries for data handling, visualization, and machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import Toplevel\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "# Importing ML models and utilities from Scikit-Learn\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60444338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style for consistent visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58402805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= DATA LOADING AND PREPROCESSING =================\n",
    "try:\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    print(\"Successfully loaded data.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data.csv: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(\"\\nColumn Data Types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype}\")\n",
    "\n",
    "# Handle missing values and drop irrelevant columns\n",
    "df = df.dropna()\n",
    "if \"profile_id\" in df.columns:\n",
    "    df = df.drop(columns=[\"profile_id\"])\n",
    "\n",
    "# Convert numeric columns to float32 for efficiency\n",
    "numeric_columns = ['u_q', 'coolant', 'stator_winding', 'u_d', 'stator_tooth', \n",
    "                   'motor_speed', 'i_d', 'i_q', 'pm', 'stator_yoke', 'ambient', 'torque']\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = df[col].astype('float32')\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {col} to float32: {e}\")\n",
    "            df[col] = df[col].fillna(0).astype('float32')\n",
    "\n",
    "# Correlation matrix visualization\n",
    "print(\"\\nGenerating correlation matrix...\")\n",
    "corr_matrix = df[numeric_columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= FEATURE SELECTION AND DATA SPLITTING =================\n",
    "features = [col for col in numeric_columns if col != 'stator_winding' and col in df.columns]\n",
    "target_regression = 'stator_winding'\n",
    "X = df[features]\n",
    "y_regression = df[target_regression].astype('float32')\n",
    "\n",
    "df['high_temperature'] = (df[target_regression] > df[target_regression].median()).astype('int32')\n",
    "y_classification = df['high_temperature']\n",
    "\n",
    "# Train-test split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.2, random_state=42)\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X, y_classification, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "scaler_cls = StandardScaler()\n",
    "X_train_cls_scaled = scaler_cls.fit_transform(X_train_cls)\n",
    "X_test_cls_scaled = scaler_cls.transform(X_test_cls)\n",
    "\n",
    "print(\"Data scaling and splitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2244b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ================= MACHINE LEARNING MODELS =================##\n",
    "\n",
    "# ===== LINEAR REGRESSION MODEL =====\n",
    "print(\"\\n===== Training Linear Regression Model =====\")\n",
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(X_train_reg_scaled, y_train_reg)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_reg = lin_reg_model.predict(X_test_reg_scaled)\n",
    "\n",
    "# Evaluate regression model\n",
    "r2_test = r2_score(y_test_reg, y_pred_reg)\n",
    "mae_test = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "mse_test = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(f\"Linear Regression - Test RÂ² Score: {r2_test:.4f}\")\n",
    "print(f\"Linear Regression - Test MAE: {mae_test:.4f}\")\n",
    "print(f\"Linear Regression - Test MSE: {mse_test:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "r2_train = r2_score(y_train_reg, lin_reg_model.predict(X_train_reg_scaled))\n",
    "if r2_train - r2_test > 0.05:\n",
    "    print(\"Warning: Potential Overfitting! Train score is much higher than test score.\")\n",
    "else:\n",
    "    print(\"No significant overfitting detected.\")\n",
    "\n",
    "# ===== LOGISTIC REGRESSION MODEL =====\n",
    "print(\"\\n===== Training Logistic Regression Model =====\")\n",
    "log_reg_model = LogisticRegression(max_iter=1000)\n",
    "log_reg_model.fit(X_train_cls_scaled, y_train_cls)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log = log_reg_model.predict(X_test_cls_scaled)\n",
    "\n",
    "# Evaluate logistic regression model\n",
    "accuracy_log = accuracy_score(y_test_cls, y_pred_log)\n",
    "print(f\"Logistic Regression - Test Accuracy: {accuracy_log:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cls, y_pred_log))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cls, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dabeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SVM MODEL =====\n",
    "print(\"\\n===== Training SVM Model =====\")\n",
    "svm_model = LinearSVC(penalty='l2', C=0.1, max_iter=1000, class_weight='balanced')\n",
    "svm_model.fit(X_train_cls_scaled, y_train_cls)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test_cls_scaled)\n",
    "\n",
    "# Evaluate SVM model\n",
    "accuracy_svm = accuracy_score(y_test_cls, y_pred_svm)\n",
    "print(f\"SVM - Test Accuracy: {accuracy_svm:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cls, y_pred_svm))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cls, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== KMEANS CLUSTERING =====\n",
    "(\"\\n===== Training KMeans Clustering =====\")\n",
    "\n",
    "# Downsample training data (e.g., use only 20% of original data)\n",
    "X_train_cls_sampled, _, y_train_cls_sampled, _ = train_test_split(\n",
    "    X_train_cls_scaled, y_train_cls, test_size=0.8, random_state=42\n",
    ")\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=2, random_state=42, n_init=10, max_iter=100)\n",
    "kmeans_model.fit(X_train_cls_scaled)\n",
    "\n",
    "# Predict clusters for test data\n",
    "y_pred_clusters = kmeans_model.predict(X_test_cls_scaled)\n",
    "\n",
    "# Map clusters to actual class labels (fixed version)\n",
    "def map_clusters_to_labels(y_true, y_pred):\n",
    "    # Convert to numpy arrays to avoid pandas indexing issues\n",
    "    y_true_np = np.array(y_true)\n",
    "    y_pred_np = np.array(y_pred)\n",
    "    \n",
    "    label_mapping = {}\n",
    "    for cluster in np.unique(y_pred_np):\n",
    "        # Get indices where predictions equal current cluster\n",
    "        cluster_indices = np.where(y_pred_np == cluster)[0]\n",
    "        # Get true labels for those indices\n",
    "        actual_labels = y_true_np[cluster_indices]\n",
    "        # Find most common label (mode)\n",
    "        if len(actual_labels) > 0:\n",
    "            most_common_label = np.bincount(actual_labels.astype(int)).argmax()\n",
    "            label_mapping[cluster] = most_common_label\n",
    "    \n",
    "    # Apply the mapping\n",
    "    return np.array([label_mapping.get(cluster, 0) for cluster in y_pred_np])\n",
    "\n",
    "# Map predicted clusters to the closest actual class\n",
    "y_pred_kmeans = map_clusters_to_labels(y_test_cls, y_pred_clusters)\n",
    "\n",
    "# Evaluate KMeans model\n",
    "accuracy_kmeans = accuracy_score(y_test_cls, y_pred_kmeans)\n",
    "print(f\"KMeans - Test Accuracy: {accuracy_kmeans:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cls, y_pred_kmeans))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cls, y_pred_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================= GUI IMPLEMENTATION =================\n",
    "def show_correlation_matrix():\n",
    "    window = Toplevel(root)\n",
    "    window.title(\"Correlation Matrix\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', ax=ax)\n",
    "    ax.set_title('Correlation Matrix of Motor Data Variables')\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, master=window)\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "    canvas.draw()\n",
    "\n",
    "def show_linear_regression():\n",
    "    window = Toplevel(root)\n",
    "    window.title(\"Linear Regression Results\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Predicted vs Actual values\n",
    "    ax1.scatter(y_test_reg, y_pred_reg, color=\"blue\", alpha=0.5)\n",
    "    ax1.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], \n",
    "             color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_xlabel(\"Actual Motor Speed\")\n",
    "    ax1.set_ylabel(\"Predicted Motor Speed\")\n",
    "    ax1.set_title(\"Predicted vs Actual Values\")\n",
    "    \n",
    "    # Plot 2: Residuals\n",
    "    residuals = y_test_reg - y_pred_reg\n",
    "    ax2.scatter(y_pred_reg, residuals, color=\"green\", alpha=0.5)\n",
    "    ax2.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
    "    ax2.set_xlabel(\"Predicted Values\")\n",
    "    ax2.set_ylabel(\"Residuals\")\n",
    "    ax2.set_title(\"Residual Plot\")\n",
    "    \n",
    "    # Add metrics as text\n",
    "    metrics_text = f\"RÂ² Score: {r2_test:.4f}\\nMAE: {mae_test:.4f}\\nMSE: {mse_test:.4f}\"\n",
    "    fig.text(0.5, 0.01, metrics_text, ha='center', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, master=window)\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "    canvas.draw()\n",
    "\n",
    "def show_logistic_regression():\n",
    "    window = Toplevel(root)\n",
    "    window.title(\"Logistic Regression Results\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_cls, y_pred_log)\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax1)\n",
    "    ax1.set_xlabel(\"Predicted\")\n",
    "    ax1.set_ylabel(\"Actual\")\n",
    "    ax1.set_title(\"Confusion Matrix\")\n",
    "    \n",
    "    # Plot 2: Feature Importance\n",
    "    if hasattr(log_reg_model, 'coef_'):\n",
    "        importance = np.abs(log_reg_model.coef_[0])\n",
    "        feature_names = X.columns\n",
    "        \n",
    "        # Sort feature importances\n",
    "        sorted_idx = np.argsort(importance)\n",
    "        ax2.barh(range(len(sorted_idx)), importance[sorted_idx], align='center')\n",
    "        ax2.set_yticks(range(len(sorted_idx)))\n",
    "        ax2.set_yticklabels([feature_names[i] for i in sorted_idx])\n",
    "        ax2.set_title(\"Feature Importance\")\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, \"Feature importance not available\", \n",
    "                ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    # Add accuracy as text\n",
    "    fig.text(0.5, 0.01, f\"Accuracy: {accuracy_log:.4f}\", ha='center', fontsize=12,\n",
    "             bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, master=window)\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "    canvas.draw()\n",
    "\n",
    "def show_svm():\n",
    "    window = Toplevel(root)\n",
    "    window.title(\"SVM Results\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_cls, y_pred_svm)\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax1)\n",
    "    ax1.set_xlabel(\"Predicted\")\n",
    "    ax1.set_ylabel(\"Actual\")\n",
    "    ax1.set_title(\"Confusion Matrix\")\n",
    "    \n",
    "    # Plot 2: Feature Importance\n",
    "    if hasattr(svm_model, 'coef_'):\n",
    "        importance = np.abs(svm_model.coef_[0])\n",
    "        feature_names = X.columns\n",
    "        \n",
    "        # Sort feature importances\n",
    "        sorted_idx = np.argsort(importance)\n",
    "        ax2.barh(range(len(sorted_idx)), importance[sorted_idx], align='center')\n",
    "        ax2.set_yticks(range(len(sorted_idx)))\n",
    "        ax2.set_yticklabels([feature_names[i] for i in sorted_idx])\n",
    "        ax2.set_title(\"Feature Importance\")\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, \"Feature importance not available\", \n",
    "                ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    # Add accuracy as text\n",
    "    fig.text(0.5, 0.01, f\"Accuracy: {accuracy_svm:.4f}\", ha='center', fontsize=12,\n",
    "             bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, master=window)\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "    canvas.draw()\n",
    "\n",
    "def show_kmeans():\n",
    "    window = Toplevel(root)\n",
    "    window.title(\"KMeans Clustering Results\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_cls, y_pred_kmeans)\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax1)\n",
    "    ax1.set_xlabel(\"Predicted\")\n",
    "    ax1.set_ylabel(\"Actual\")\n",
    "    ax1.set_title(\"Confusion Matrix\")\n",
    "    \n",
    "    # Plot 2: Cluster Visualization\n",
    "   # Reduce number of points plotted by selecting a random subset (e.g., 10% of data)\n",
    "    num_samples = int(0.0005 * len(X_test_cls_scaled))  # Take only 10% of the data\n",
    "    sample_indices = np.random.choice(len(X_test_cls_scaled), size=num_samples, replace=False)\n",
    "\n",
    "# Select only sampled points\n",
    "    X_sampled = X_test_cls_scaled[sample_indices]\n",
    "    y_pred_sampled = y_pred_clusters[sample_indices]\n",
    "\n",
    "# Plot only the sampled points\n",
    "    scatter = ax2.scatter(X_sampled[:, 0], X_sampled[:, 1], \n",
    "                      c=y_pred_sampled, cmap='viridis', alpha=0.8)\n",
    "\n",
    "\n",
    "    ax2.set_xlabel(features[0])\n",
    "    ax2.set_ylabel(features[1])\n",
    "    ax2.set_title(\"Cluster Visualization\")\n",
    "    plt.colorbar(scatter, ax=ax2)\n",
    "    \n",
    "    # Add accuracy as text\n",
    "    fig.text(0.5, 0.01, f\"Accuracy: {accuracy_kmeans:.4f}\", ha='center', fontsize=12,\n",
    "             bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, master=window)\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "    canvas.draw()\n",
    "\n",
    "# Create main GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Motor Data Analysis - ML Model Comparison\")\n",
    "root.geometry(\"600x500\")\n",
    "\n",
    "# Add title and description\n",
    "title_label = tk.Label(root, text=\"Motor Data Analysis Dashboard\", font=(\"Arial\", 16, \"bold\"))\n",
    "title_label.pack(pady=10)\n",
    "\n",
    "description = \"\"\"\n",
    "This application analyzes motor data using various machine learning models.\n",
    "Choose a model or visualization method below to see detailed results.\n",
    "\"\"\"\n",
    "desc_label = tk.Label(root, text=description, justify=tk.LEFT, padx=20)\n",
    "desc_label.pack(pady=10)\n",
    "\n",
    "# Create a frame for buttons\n",
    "button_frame = tk.Frame(root)\n",
    "button_frame.pack(pady=20)\n",
    "\n",
    "# Create buttons with improved styling\n",
    "button_style = {\"width\": 25, \"height\": 2, \"font\": (\"Arial\", 10), \"bg\": \"#e0e0e0\"}\n",
    "\n",
    "btn_corr = tk.Button(button_frame, text=\"Correlation Matrix\", command=show_correlation_matrix, **button_style)\n",
    "btn_corr.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "btn_linreg = tk.Button(button_frame, text=\"Linear Regression\", command=show_linear_regression, **button_style)\n",
    "btn_linreg.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "btn_logreg = tk.Button(button_frame, text=\"Logistic Regression\", command=show_logistic_regression, **button_style)\n",
    "btn_logreg.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "btn_svm = tk.Button(button_frame, text=\"SVM Classification\", command=show_svm, **button_style)\n",
    "btn_svm.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "btn_kmeans = tk.Button(button_frame, text=\"KMeans Clustering\", command=show_kmeans, **button_style)\n",
    "btn_kmeans.grid(row=2, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "# Add status information\n",
    "status_text = f\"Data loaded: {df.shape[0]} samples, {df.shape[1]} features\"\n",
    "status_label = tk.Label(root, text=status_text, bd=1, relief=tk.SUNKEN, anchor=tk.W)\n",
    "status_label.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "# Run the GUI main loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
